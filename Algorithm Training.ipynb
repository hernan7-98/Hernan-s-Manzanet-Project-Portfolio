{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcdc5507-b800-48b1-bdb0-fa42d918f74d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "794b298f-30a1-45fc-968e-1f5918fa0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca2889a8-0d04-4f80-b6c0-b520e692a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', as_frame = False, parser = 'auto') #return Numpy arrays. to get a dataframe set as_frame = True\n",
    "X, y = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c5fa40f-34e0-48ee-a494-f90f63fc2d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xdev, Xtest = X[:50000], X[50000:60000], X[60000:]\n",
    "ytrain, ydev, ytest = y[:50000], y[50000:60000], y[60000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a74a2659-03e3-47b5-9fbe-dc6a2b6d87a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the dev set: 97.18%\n",
      "Accuracy on the test set: 96.64%\n",
      "F1 score on the dev set: 97.17%\n",
      "F1 score on the test set: 96.63%\n",
      "Recall on the dev set: 97.18%\n",
      "Recall on the test set: 96.64%\n",
      "Precision on the dev set: 97.20%\n",
      "Precision on the test set: 96.67%\n"
     ]
    }
   ],
   "source": [
    "#KNeighborsClassifier\n",
    "\n",
    "#KNN classifier \n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Flatten the images\n",
    "Xtrain_flat = Xtrain.reshape((Xtrain.shape[0], -1))\n",
    "Xdev_flat = Xdev.reshape((Xdev.shape[0], -1))\n",
    "Xtest_flat = Xtest.reshape((Xtest.shape[0], -1))\n",
    "\n",
    "# Fit the classifier on the flattened training data\n",
    "knn_classifier.fit(Xtrain_flat, ytrain)\n",
    "\n",
    "#predictions on the development (validation) set\n",
    "ydev_pred = knn_classifier.predict(Xdev_flat)\n",
    "\n",
    "#accuracy on the development set\n",
    "accuracy_knn = accuracy_score(ydev, ydev_pred)\n",
    "print(f\"Accuracy on the dev set: {accuracy_knn:.2%}\")\n",
    "\n",
    "#predictions on the test set\n",
    "ytest_pred = knn_classifier.predict(Xtest_flat)\n",
    "\n",
    "#accuracy on the test set\n",
    "accuracy_test = accuracy_score(ytest, ytest_pred)\n",
    "print(f\"Accuracy on the test set: {accuracy_test:.2%}\")\n",
    "\n",
    "#F1 score on the development set\n",
    "f1_knn = f1_score(ydev, ydev_pred, average='weighted')\n",
    "print(f\"F1 score on the dev set: {f1_knn:.2%}\")\n",
    "#F1 score on the test set\n",
    "f1_test = f1_score(ytest, ytest_pred, average='weighted')\n",
    "print(f\"F1 score on the test set: {f1_test:.2%}\")\n",
    "\n",
    "#recall score on the development set\n",
    "recall_knn = recall_score(ydev, ydev_pred, average='weighted')\n",
    "print(f\"Recall on the dev set: {recall_knn:.2%}\")\n",
    "#recall score on the test set\n",
    "recall_test = recall_score(ytest, ytest_pred, average='weighted')\n",
    "print(f\"Recall on the test set: {recall_test:.2%}\")\n",
    "\n",
    "#precision score on the development set\n",
    "precision_knn = precision_score(ydev, ydev_pred, average='weighted')\n",
    "print(f\"Precision on the dev set: {precision_knn:.2%}\")\n",
    "\n",
    "#precision score on the test set\n",
    "precision_test = precision_score(ytest, ytest_pred, average='weighted')\n",
    "print(f\"Precision on the test set: {precision_test:.2%}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "853f6a53-612f-4c97-a2e4-abe4e87648f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the dev set: 87.39%\n",
      "Accuracy on the test set: 86.77%\n",
      "F1 score on the SGD dev set: 87.51%\n",
      "F1 score on the test set: 86.97%\n",
      "Recall on the SGD dev set: 87.39%\n",
      "Recall on the SGD test set: 86.77%\n",
      "Precision on the SGD dev set: 88.25%\n",
      "Precision on the SGD test set: 87.99%\n"
     ]
    }
   ],
   "source": [
    "#SGD Classifier\n",
    "\n",
    "sgd_classifier = SGDClassifier(random_state=42)\n",
    "\n",
    "Xtrain_flat = Xtrain.reshape((Xtrain.shape[0], -1))\n",
    "Xdev_flat = Xdev.reshape((Xdev.shape[0], -1))\n",
    "Xtest_flat = Xtest.reshape((Xtest.shape[0], -1))\n",
    "\n",
    "sgd_classifier.fit(Xtrain_flat, ytrain)\n",
    "\n",
    "ydev_pred = sgd_classifier.predict(Xdev_flat)\n",
    "\n",
    "accuracy_sgd = accuracy_score(ydev, ydev_pred)\n",
    "print(f\"Accuracy on the dev set: {accuracy_sgd:.2%}\")\n",
    "\n",
    "ytest_pred = sgd_classifier.predict(Xtest_flat)\n",
    "\n",
    "accuracy_test = accuracy_score(ytest, ytest_pred)\n",
    "print(f\"Accuracy on the test set: {accuracy_test:.2%}\")\n",
    "#F1\n",
    "f1_sgd = f1_score(ydev, ydev_pred, average='weighted')\n",
    "print(f\"F1 score on the SGD dev set: {f1_sgd:.2%}\")\n",
    "f1_test = f1_score(ytest, ytest_pred, average='weighted')\n",
    "print(f\"F1 score on the test set: {f1_test:.2%}\")\n",
    "\n",
    "#Recall\n",
    "recall_sgd = recall_score(ydev, ydev_pred, average='weighted')\n",
    "print(f\"Recall on the SGD dev set: {recall_sgd:.2%}\")\n",
    "recall_test = recall_score(ytest, ytest_pred, average='weighted')\n",
    "print(f\"Recall on the SGD test set: {recall_test:.2%}\")\n",
    "\n",
    "#Precision\n",
    "\n",
    "precision_sgd = precision_score(ydev, ydev_pred, average='weighted')\n",
    "print(f\"Precision on the SGD dev set: {precision_sgd:.2%}\")\n",
    "precision_test = precision_score(ytest, ytest_pred, average='weighted')\n",
    "print(f\"Precision on the SGD test set: {precision_test:.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57ba6744-605a-4b81-8d4d-1ea1b3b61b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/LC/manzhe01/.local/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/LC/manzhe01/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the dev set: 85.78%\n",
      "Accuracy on the test set: 85.98%\n",
      "F1 score on the LinearSVC dev set: 85.83%\n",
      "F1 score on the LinearSVC test set: 86.00%\n",
      "Recall on the LinearSVC dev set: 85.78%\n",
      "Recall on the LinearSVC test set: 85.98%\n",
      "Precision on the LinearSVC dev set: 86.89%\n",
      "Precision on the LinearSVC test set: 86.94%\n"
     ]
    }
   ],
   "source": [
    "#LinearSVC classifier\n",
    "linear_svc_classifier = LinearSVC(random_state=42)\n",
    "\n",
    "Xtrain_flat = Xtrain.reshape((Xtrain.shape[0], -1))\n",
    "Xdev_flat = Xdev.reshape((Xdev.shape[0], -1))\n",
    "Xtest_flat = Xtest.reshape((Xtest.shape[0], -1))\n",
    "\n",
    "linear_svc_classifier.fit(Xtrain_flat, ytrain)\n",
    "\n",
    "ydev_pred = linear_svc_classifier.predict(Xdev_flat)\n",
    "\n",
    "accuracy_svc = accuracy_score(ydev, ydev_pred)\n",
    "print(f\"Accuracy on the dev set: {accuracy_svc:.2%}\")\n",
    "\n",
    "ytest_pred = linear_svc_classifier.predict(Xtest_flat)\n",
    "\n",
    "accuracy_test = accuracy_score(ytest, ytest_pred)\n",
    "print(f\"Accuracy on the test set: {accuracy_test:.2%}\")\n",
    "\n",
    "\n",
    "\n",
    "f1_svc = f1_score(ydev, ydev_pred, average='weighted')\n",
    "print(f\"F1 score on the LinearSVC dev set: {f1_svc:.2%}\")\n",
    "\n",
    "f1_test = f1_score(ytest, ytest_pred, average='weighted')\n",
    "print(f\"F1 score on the LinearSVC test set: {f1_test:.2%}\")\n",
    "\n",
    "\n",
    "recall_svc = recall_score(ydev, ydev_pred, average='weighted')\n",
    "print(f\"Recall on the LinearSVC dev set: {recall_svc:.2%}\")\n",
    "recall_test = recall_score(ytest, ytest_pred, average='weighted')\n",
    "print(f\"Recall on the LinearSVC test set: {recall_test:.2%}\")\n",
    "\n",
    "\n",
    "precision_svc = precision_score(ydev, ydev_pred, average='weighted')\n",
    "print(f\"Precision on the LinearSVC dev set: {precision_svc:.2%}\")\n",
    "precision_test = precision_score(ytest, ytest_pred, average='weighted')\n",
    "print(f\"Precision on the LinearSVC test set: {precision_test:.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "442ed74c-6613-4819-a3d7-a70af535ff12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the dev set: 88.22%\n",
      "Accuracy on the test set: 86.93%\n",
      "F1 score on the DecisionTree dev set: 88.21%\n",
      "F1 score on the DecisionTree test set: 86.90%\n",
      "Recall on the DecisionTree dev set: 88.22%\n",
      "Recall on the DecisionTree test set: 86.93%\n",
      "Precision on the DecisionTree dev set: 88.21%\n",
      "Precision on the DecisionTree test set: 86.91%\n"
     ]
    }
   ],
   "source": [
    "#DecisionTree\n",
    "decision_tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "Xtrain_flat = Xtrain.reshape((Xtrain.shape[0], -1))\n",
    "Xdev_flat = Xdev.reshape((Xdev.shape[0], -1))\n",
    "Xtest_flat = Xtest.reshape((Xtest.shape[0], -1))\n",
    "decision_tree_classifier.fit(Xtrain_flat, ytrain)\n",
    "ydev_pred = decision_tree_classifier.predict(Xdev_flat)\n",
    "accuracy_tree = accuracy_score(ydev, ydev_pred)\n",
    "print(f\"Accuracy on the dev set: {accuracy_tree:.2%}\")\n",
    "ytest_pred = decision_tree_classifier.predict(Xtest_flat)\n",
    "accuracy_test = accuracy_score(ytest, ytest_pred)\n",
    "print(f\"Accuracy on the test set: {accuracy_test:.2%}\")\n",
    "# Make predictions on the development (validation) set\n",
    "ydev_pred = decision_tree_classifier.predict(Xdev_flat)\n",
    "\n",
    "#F1 score on the development set\n",
    "f1_tree = f1_score(ydev, ydev_pred, average='weighted')\n",
    "print(f\"F1 score on the DecisionTree dev set: {f1_tree:.2%}\")\n",
    "#F1 score on the test set\n",
    "f1_test = f1_score(ytest, ytest_pred, average='weighted')\n",
    "print(f\"F1 score on the DecisionTree test set: {f1_test:.2%}\")\n",
    "\n",
    "#recall score on the development set\n",
    "recall_tree = recall_score(ydev, ydev_pred, average='weighted')\n",
    "print(f\"Recall on the DecisionTree dev set: {recall_tree:.2%}\")\n",
    "#recall score on the test set\n",
    "recall_test = recall_score(ytest, ytest_pred, average='weighted')\n",
    "print(f\"Recall on the DecisionTree test set: {recall_test:.2%}\")\n",
    "\n",
    "#precision score on the development set\n",
    "precision_tree = precision_score(ydev, ydev_pred, average='weighted')\n",
    "print(f\"Precision on the DecisionTree dev set: {precision_tree:.2%}\")\n",
    "#precision score on the test set\n",
    "precision_test = precision_score(ytest, ytest_pred, average='weighted')\n",
    "print(f\"Precision on the DecisionTree test set: {precision_test:.2%}\")\n",
    "\n",
    "#predictions on the test set\n",
    "ytest_pred = decision_tree_classifier.predict(Xtest_flat)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57f2812b-fd83-49b1-a0b8-759809208351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/LC/manzhe01/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the LogisticRegression test set: 92.43%\n",
      "Accuracy on the LogisticRegression dev set: 92.72%\n",
      "F1 score on the LogisticRegression dev set: 92.70%\n",
      "F1 score on the LogisticRegression test set: 92.41%\n",
      "Recall on the LogisticRegression dev set: 92.72%\n",
      "Recall on the LogisticRegression test set: 92.43%\n",
      "Precision on the LogisticRegression dev set: 92.69%\n",
      "Precision on the LogisticRegression test set: 92.42%\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "logistic_regression_classifier = LogisticRegression(random_state=42, max_iter=100)\n",
    "Xtrain_flat = Xtrain.reshape((Xtrain.shape[0], -1))\n",
    "Xdev_flat = Xdev.reshape((Xdev.shape[0], -1))\n",
    "Xtest_flat = Xtest.reshape((Xtest.shape[0], -1))\n",
    "logistic_regression_classifier.fit(Xtrain_flat, ytrain)\n",
    "#predictions on the development (validation) set\n",
    "ydev_pred = logistic_regression_classifier.predict(Xdev_flat)\n",
    "#predictions on the test set\n",
    "ytest_pred = logistic_regression_classifier.predict(Xtest_flat)\n",
    "#accuracy on the test set\n",
    "accuracy_test = accuracy_score(ytest, ytest_pred)\n",
    "print(f\"Accuracy on the LogisticRegression test set: {accuracy_test:.2%}\")\n",
    "#accuracy on the development set\n",
    "accuracy_logreg = accuracy_score(ydev, ydev_pred)\n",
    "print(f\"Accuracy on the LogisticRegression dev set: {accuracy_logreg:.2%}\")\n",
    "\n",
    "\n",
    "#predictions on the development (validation) set\n",
    "ydev_pred = logistic_regression_classifier.predict(Xdev_flat)\n",
    "\n",
    "#F1 score on the development set\n",
    "f1_logreg = f1_score(ydev, ydev_pred, average='weighted')\n",
    "print(f\"F1 score on the LogisticRegression dev set: {f1_logreg:.2%}\")\n",
    "#predictions on the test set\n",
    "ytest_pred = logistic_regression_classifier.predict(Xtest_flat)\n",
    "\n",
    "#F1 score on the test set\n",
    "f1_test = f1_score(ytest, ytest_pred, average='weighted')\n",
    "print(f\"F1 score on the LogisticRegression test set: {f1_test:.2%}\")\n",
    "\n",
    "#recall score on the development set\n",
    "recall_logreg = recall_score(ydev, ydev_pred, average='weighted')\n",
    "print(f\"Recall on the LogisticRegression dev set: {recall_logreg:.2%}\")\n",
    "#recall score on the test set\n",
    "recall_test = recall_score(ytest, ytest_pred, average='weighted')\n",
    "print(f\"Recall on the LogisticRegression test set: {recall_test:.2%}\")\n",
    "\n",
    "#precision score on the development set\n",
    "precision_logreg = precision_score(ydev, ydev_pred, average='weighted')\n",
    "print(f\"Precision on the LogisticRegression dev set: {precision_logreg:.2%}\")\n",
    "#precision score on the test set\n",
    "precision_test = precision_score(ytest, ytest_pred, average='weighted')\n",
    "print(f\"Precision on the LogisticRegression test set: {precision_test:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8465f87-1e66-46d8-a1aa-20a610c3bbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Algorithm  Accuracy  Precision  Recall  F1 Score\n",
      "0         SGDClassifier    0.8739   0.882472  0.8739  0.875077\n",
      "1             LinearSVC    0.8578   0.868867  0.8578  0.858331\n",
      "2  KNeighborsClassifier    0.9718   0.972000  0.9718  0.971737\n",
      "3    LogisticRegression    0.9272   0.926883  0.9272  0.926951\n",
      "4          DecisionTree    0.8822   0.882139  0.8822  0.882090\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the scores for each algorithm\n",
    "scores = {\n",
    "    'Algorithm': ['SGDClassifier', 'LinearSVC', 'KNeighborsClassifier', 'LogisticRegression', 'DecisionTree'],\n",
    "    'Accuracy': [accuracy_sgd, accuracy_svc, accuracy_knn, accuracy_logreg, accuracy_tree],\n",
    "    'Precision': [precision_sgd, precision_svc, precision_knn, precision_logreg, precision_tree],\n",
    "    'Recall': [recall_sgd, recall_svc, recall_knn, recall_logreg, recall_tree],\n",
    "    'F1 Score': [f1_sgd, f1_svc, f1_knn, f1_logreg, f1_tree]\n",
    "}\n",
    "\n",
    "# Create a Pandas DataFrame from the scores dictionary\n",
    "df = pd.DataFrame(scores)\n",
    "\n",
    "# Print the table for comparison\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2ccc685-0312-4241-8f2d-81ca57fa8d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the development set: 96.95%\n",
      "Accuracy on the test set: 96.73%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  \n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_dev_pred = knn.predict(X_dev)\n",
    "\n",
    "y_test_pred = knn.predict(X_test)\n",
    "\n",
    "dev_accuracy = accuracy_score(y_dev, y_dev_pred)\n",
    "print(f\"Accuracy on the development set: {dev_accuracy * 100:.2f}%\")\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Accuracy on the test set: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3c23c9-1f22-4065-bffa-6881727222c5",
   "metadata": {},
   "source": [
    "We can see that the KNeighborsClassifier  algorithm worked the best because of its accuracy on every score is higher comapred to the other algorithms.\n",
    "\n",
    "Accuracy: Among the algorithms, KNeighborsClassifier achieved the highest accuracy (97.18%), indicating that it correctly classified a significant portion of the data.\n",
    "\n",
    "Precision: KNeighborsClassifier also has the highest precision (97.20%), suggesting that when it predicts a positive class, it is accurate.\n",
    "\n",
    "Recall: KNeighborsClassifier's recall (97.18%) is very high, indicating that it effectively captures most of the positive class instances.\n",
    "\n",
    "F1 Score: KNeighborsClassifier has the highest F1 score (97.17%), which is a balance between precision and recall. It suggests a strong overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f2b685-63de-4be6-8060-432c53509e19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS420 (Python3.8)",
   "language": "python",
   "name": "ds420"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
